# 200名同時アクセス向け 設計・スケーリング

Resonance Logger を **約200名の同時アクセス** で使うことを想定した設計メモと実装上のポイントです。

---

## 1. 参加者画面（クライアント）

### 1.1 タップのスロットル（ResonanceButton）
- **目的**: 1人あたりの連打でバックエンドやストレージへの書き込みが爆発しないようにする。
- **実装**: `TAP_THROTTLE_MS = 280` — この間隔より短い連打は **1回としてのみ** カウント・送信する。
- **効果**: 200人が同時に連打しても、送信レートの上限が「200 × (1000/280) ≒ 約700/秒」程度に抑えられる（実際はタップ頻度はもっと低い想定）。

### 1.2 ログ件数上限（ParticipantView）
- **目的**: メモリ・localStorage 肥大化と、大きな配列による再描画負荷を防ぐ。
- **実装**: `MAX_LOG_LENGTH = 500`。ログは常に **直近500件** のみ保持。読み込み時・追加時ともにトリム。
- **効果**: 長時間・多タップでも配列サイズが一定で、UI が重くなりにくい。

### 1.3 localStorage 保存の debounce（ParticipantView）
- **目的**: タップのたびに `localStorage.setItem` を呼ばないようにする。
- **実装**: ログが変わるたびに **600ms 遅延** で保存。その間に再度変更があればタイマーをやり直し、落ち着いた時点で1回だけ保存。
- **効果**: 連打時でも書き込み回数が少なくなり、メインスレッドとストレージ I/O の負荷を軽減。

### 1.4 MyLog の計算対象件数（MyLog）
- **目的**: グラフ用の集計で、極端に長い配列を走査しないようにする。
- **実装**: 集計には **直近 800 件** のタイムスタンプのみ使用（`MAX_TIMESTAMPS_FOR_CHART`）。
- **効果**: タップ数が多くても useMemo 内のループが一定規模に抑えられ、描画が重くなりにくい。

---

## 2. ダッシュボード（クライアント）

### 2.1 チャートのデータ点数
- **実装**: `MAX_POINTS = 80`。時系列は **直近80点** までに制限。
- **効果**: DOM ・描画コストが増えすぎない。

### 2.2 本番時のデータ購読（推奨）
- **推奨**: ダッシュボードは **「集約済み1ストリーム」だけ** を購読する。
- **避けること**: 200人分の個別タップストリームをそのまま 200 本購読しない。
- **例（Firebase）**:
  - 各参加者: 自分のタップを `/taps/{userId}` などに書き込み。
  - バックエンド（Cloud Functions 等）: 一定間隔（例: 5秒や1分）で `/taps/*` を集計し、`/aggregate/byMinute` のような **1本の集約データ** にだけ書き込む。
  - ダッシュボード: `onValue(ref(db, 'aggregate/byMinute'))` のみ購読し、その結果でチャートを更新。
- **効果**: 同時接続数が増えても、ダッシュボードの受信・再描画は「集約ストリームの更新頻度」に依存し、スケールしやすい。

---

## 3. バックエンド接続時（本番想定）

- **書き込み**: 参加者 200 人 × スロットル後のタップ頻度。Firebase 等の同時書き込み制限に収まる設計（上記スロットル・集約で調整）。
- **読み取り**: ダッシュボードは集約データのみ購読するため、読み取りは「集約用の1パス」が中心になる。
- **オフライン**: 参加者側で一時的にキューに溜め、復帰時に送る方式を検討すると、会場ネットワークの揺れに強い。

---

## 4. まとめ

| 観点           | 対策 |
|----------------|------|
| 参加者・連打   | タップのスロットル（280ms） |
| 参加者・ストレージ | ログ 500 件上限、保存 debounce 600ms |
| 参加者・描画   | MyLog 集計は直近 800 件まで |
| ダッシュボード | チャート 80 点まで、本番は集約ストリームのみ購読 |

これらにより、約200名の同時アクセスでもクライアントと（本番時の）バックエンド負荷を抑えつつ運用できるようにしています。
